{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import Levenshtein\n",
    "\n",
    "#PRETRAIN_GRNAS_PATH = '../data/main_dataframes/pretrain_grnas.csv'\n",
    "PRETRAIN_GRNAS_PATH = 'crispr_on_grnas.csv'\n",
    "LEENAY_PATH = 'leenay_full_data.csv'\n",
    "U6T7_PATH = '13059_2016_1012_MOESM14_ESM.tsv'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pretrain_grnas(no_GG = False):\n",
    "    pretrain_grnas = pd.read_csv(PRETRAIN_GRNAS_PATH)\n",
    "    pretrain_grnas = set(pretrain_grnas['sequence'].values)\n",
    "\n",
    "    if no_GG:\n",
    "        # remove the last two characters from each sequence\n",
    "        pretrain_grnas = set([seq[:-2] for seq in pretrain_grnas])\n",
    "    \n",
    "    return pretrain_grnas\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_leaking(seq, grnas_set):\n",
    "    for grna in grnas_set:\n",
    "        distance = Levenshtein.hamming(seq, grna)\n",
    "        if distance < 4:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_leakage_leenay():\n",
    "    leenay_df=  pd.read_csv(LEENAY_PATH)\n",
    "\n",
    "    # print the number of sequences\n",
    "    print('Number of sequences before removing leakage:', len(leenay_df))\n",
    "\n",
    "    pretrain_grnas = get_pretrain_grnas(no_GG=True)\n",
    "    leenay_df['is_leaking'] = leenay_df['21mer'].apply(lambda x: is_leaking(x, pretrain_grnas))\n",
    "    leenay_df = leenay_df[leenay_df['is_leaking'] == False]\n",
    "    # remove the is_leaking column\n",
    "    leenay_df = leenay_df.drop(columns=['is_leaking'])\n",
    "\n",
    "    leenay_df.to_csv('leenay_no_leakage.csv', index=False)\n",
    "\n",
    "    # print the number of sequences\n",
    "    print('Number of sequences after removing leakage:', len(leenay_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences before removing leakage: 1555\n",
      "Number of sequences after removing leakage: 1539\n"
     ]
    }
   ],
   "source": [
    "remove_leakage_leenay()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_leakage_U6T7():\n",
    "    u6t7_df = pd.read_csv(U6T7_PATH, sep='\\t')\n",
    "\n",
    "    # print the number of sequences\n",
    "    print('Number of sequences before removing leakage:', len(u6t7_df))\n",
    "\n",
    "    pretrain_grnas = get_pretrain_grnas(no_GG=False)\n",
    "    u6t7_df['is_leaking'] = u6t7_df['seq'].apply(lambda x: is_leaking(x, pretrain_grnas))\n",
    "    u6t7_df = u6t7_df[u6t7_df['is_leaking'] == False]\n",
    "    # remove the is_leaking column\n",
    "    u6t7_df = u6t7_df.drop(columns=['is_leaking'])\n",
    "\n",
    "    # save to tsv\n",
    "    u6t7_df.to_csv('U6T7_no_leakage.tsv', sep='\\t', index=False)\n",
    "\n",
    "    # print the number of sequences\n",
    "    print('Number of sequences after removing leakage:', len(u6t7_df))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences before removing leakage: 31625\n",
      "Number of sequences after removing leakage: 25970\n"
     ]
    }
   ],
   "source": [
    "remove_leakage_U6T7()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hart2016-HelaLib1Avg: 4256 -> 4217\n",
      "hart2016-Hct1162lib1Avg: 4239 -> 4199\n",
      "hart2016-Rpe1Avg: 4214 -> 4175\n",
      "hart2016-HelaLib2Avg: 3845 -> 3816\n",
      "doench2016_hg19: 2333 -> 430\n",
      "doench2016plx_hg19: 2333 -> 430\n",
      "xu2015TrainKbm7: 2076 -> 2056\n",
      "xu2015TrainHl60: 2076 -> 2056\n",
      "chari2015TrainK562: 1239 -> 1198\n",
      "chari2015Train293T: 1234 -> 1193\n",
      "morenoMateos2015: 1020 -> 1017\n",
      "doench2014-Mm: 951 -> 145\n",
      "doench2014-Hs: 881 -> 110\n",
      "liu2016_mm9: 205 -> 205\n",
      "gagnon2014: 111 -> 111\n",
      "varshney2015: 102 -> 102\n",
      "shkumatavaOthers: 84 -> 84\n",
      "ghandi2016_ci2: 72 -> 72\n",
      "shkumatavaPerrine: 62 -> 62\n",
      "farboud2015: 50 -> 50\n",
      "ren2015: 39 -> 39\n",
      "xu2015: 35 -> 35\n",
      "teboulVivo_mm9: 30 -> 30\n",
      "concordet2-Hs: 26 -> 26\n",
      "xu2015AAVS1: 20 -> 20\n",
      "eschstruth: 18 -> 18\n",
      "concordet2-Mm: 18 -> 18\n",
      "shkumatavaAngelo: 17 -> 17\n",
      "schoenigRn: 15 -> 15\n",
      "xu2015FOX-AR: 15 -> 15\n",
      "schoenigMm: 6 -> 6\n",
      "schoenigHs: 3 -> 3\n"
     ]
    }
   ],
   "source": [
    "df_u6t7 = pd.read_csv(U6T7_PATH, sep='\\t')\n",
    "df_u6t7_no_leakage = pd.read_csv('U6T7_no_leakage.tsv', sep='\\t')\n",
    "\n",
    "\n",
    "# get set of all datasets\n",
    "u6t7_set = set(df_u6t7['dataset'].values)\n",
    "u6t6_set = set(df_u6t7_no_leakage['dataset'].values)\n",
    "\n",
    "# for each dataset, get the number of sequences\n",
    "set_to_size = {}\n",
    "for dataset in u6t7_set:\n",
    "    set_to_size[dataset] = len(df_u6t7[df_u6t7['dataset'] == dataset])\n",
    "\n",
    "set_to_size_no_leakage = {}\n",
    "for dataset in u6t6_set:\n",
    "    set_to_size_no_leakage[dataset] = len(df_u6t7_no_leakage[df_u6t7_no_leakage['dataset'] == dataset])\n",
    "\n",
    "\n",
    "\n",
    "# order by size\n",
    "set_to_size = {k: v for k, v in sorted(set_to_size.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "# print\n",
    "for dataset, size in set_to_size.items():\n",
    "    # print with and without leakage\n",
    "    print(f'{dataset}: {size} -> {set_to_size_no_leakage[dataset]}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
