{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import wilcoxon\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_performance(worse_method, better_method):\n",
    "    # Calculate the differences between the two sets of scores\n",
    "    differences = np.array(better_method) - np.array(worse_method)\n",
    "    \n",
    "    # Perform the Wilcoxon signed-rank test\n",
    "    stat, p_value = wilcoxon(differences, alternative='greater')\n",
    "    \n",
    "    # Output the results\n",
    "    print(\"Wilcoxon signed-rank test statistic:\", stat)\n",
    "    print(\"P-value for the hypothesis that multi-task scores are better:\", p_value)\n",
    "    return stat, p_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wilcoxon signed-rank test statistic: 55.0\n",
      "P-value for the hypothesis that multi-task scores are better: 0.0009765625\n",
      "Wilcoxon signed-rank test statistic: 55.0\n",
      "P-value for the hypothesis that multi-task scores are better: 0.0009765625\n",
      "Wilcoxon signed-rank test statistic: 55.0\n",
      "P-value for the hypothesis that multi-task scores are better: 0.0009765625\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(55.0, 0.0009765625)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "single_task_scores_hf = [0.861217413382761, 0.8524269376228074, 0.8599933187805314, 0.8636625172963411, 0.8611793128653638, 0.8561779115720118, 0.863651710896855, 0.8618047935272972, 0.8507714469824201, 0.8606244143322986]\n",
    "multi_task_scores_hf = [0.8662295843631244, 0.8645542869982946, 0.8644012893802452, 0.8642004807753318, 0.8666213764166861, 0.8653201152020525, 0.8640791681568158, 0.86666781390099, 0.8651604217755707, 0.866049004999972]\n",
    "\n",
    "single_tank_scores_esp = [0.8639322144958477, 0.8628339223802491, 0.8612067738276418, 0.8658728532548371, 0.8630890588512398, 0.861132491819325, 0.8633181230009931, 0.8634616782021346, 0.864848497034418, 0.8635930720701847]\n",
    "multi_task_scores_esp = [0.8694317679296304, 0.8671650087934266, 0.8664237555975335, 0.8673180633338209, 0.866003840209996, 0.8677087815988643, 0.8687479191104704, 0.869364678349674, 0.8678166393877942, 0.8659045521718539]\n",
    "\n",
    "single_task_scores_wt = [0.8679159457184841, 0.8683821248745178, 0.8633313545831587, 0.8656260424391291, 0.8655574516704572, 0.8632100769020945, 0.8639210962387996, 0.8672596561005766, 0.8680934013992531, 0.8679961185049415]\n",
    "multi_task_scores_wt = [0.8733294576593293, 0.8708329169383177, 0.8692321493082518, 0.8711329156686424, 0.8712039499158704, 0.8731595820834706, 0.8708950367786267, 0.8720540738245298, 0.8705329795602408, 0.8717294538728768]\n",
    "\n",
    "test_performance(single_task_scores_hf, multi_task_scores_hf)\n",
    "\n",
    "test_performance(single_tank_scores_esp, multi_task_scores_esp)\n",
    "\n",
    "test_performance(single_task_scores_wt, multi_task_scores_wt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.61058\n",
      "0.6026199999999999\n",
      "0.60246\n",
      "0.59846\n",
      "Wilcoxon signed-rank test statistic: 3.0\n",
      "P-value for the hypothesis that multi-task scores are better: 0.90625\n",
      "Wilcoxon signed-rank test statistic: 5.0\n",
      "P-value for the hypothesis that multi-task scores are better: 0.78125\n",
      "Wilcoxon signed-rank test statistic: 12.0\n",
      "P-value for the hypothesis that multi-task scores are better: 0.15625\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(12.0, 0.15625)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dhf_doench_mm_full = [0.6379,0.5962,0.5818,0.6024,0.6346]\n",
    "dhf_doench_mm_ll = [0.6158,0.5965,0.5765 ,0.6134 ,0.6109]\n",
    "dhf_doench_mm_gl = [0.6192,0.5959,0.5762,0.6102,0.6108]\n",
    "dhf_doench_mm_no_em = [0.6209,0.5853,0.5675,0.5999,0.6187]\n",
    "\n",
    "# print averages\n",
    "print(np.mean(dhf_doench_mm_full))\n",
    "print(np.mean(dhf_doench_mm_ll))\n",
    "print(np.mean(dhf_doench_mm_gl))\n",
    "print(np.mean(dhf_doench_mm_no_em))\n",
    "\n",
    "test_performance(dhf_doench_mm_full, dhf_doench_mm_gl)\n",
    "test_performance(dhf_doench_mm_ll, dhf_doench_mm_gl)\n",
    "test_performance(dhf_doench_mm_no_em, dhf_doench_mm_gl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "leenay \n",
      "Wilcoxon signed-rank test statistic: 15.0\n",
      "P-value for the hypothesis that multi-task scores are better: 0.03125\n",
      "\n",
      "\n",
      "chari2015Train293T \n",
      "Wilcoxon signed-rank test statistic: 2.0\n",
      "P-value for the hypothesis that multi-task scores are better: 0.9375\n",
      "\n",
      "\n",
      "doench2014-Hs \n",
      "Wilcoxon signed-rank test statistic: 12.0\n",
      "P-value for the hypothesis that multi-task scores are better: 0.15625\n",
      "\n",
      "\n",
      "doench2014-Mm \n",
      "Wilcoxon signed-rank test statistic: 15.0\n",
      "P-value for the hypothesis that multi-task scores are better: 0.03125\n",
      "\n",
      "\n",
      "doench2016_hg19 \n",
      "Wilcoxon signed-rank test statistic: 7.0\n",
      "P-value for the hypothesis that multi-task scores are better: 0.59375\n",
      "\n",
      "\n",
      "doench2016plx_hg19 \n",
      "Wilcoxon signed-rank test statistic: 11.0\n",
      "P-value for the hypothesis that multi-task scores are better: 0.21875\n",
      "\n",
      "\n",
      "hart2016-Hct1162lib1Avg \n",
      "Wilcoxon signed-rank test statistic: 15.0\n",
      "P-value for the hypothesis that multi-task scores are better: 0.03125\n",
      "\n",
      "\n",
      "hart2016-HelaLib1Avg \n",
      "Wilcoxon signed-rank test statistic: 15.0\n",
      "P-value for the hypothesis that multi-task scores are better: 0.03125\n",
      "\n",
      "\n",
      "hart2016-HelaLib2Avg \n",
      "Wilcoxon signed-rank test statistic: 15.0\n",
      "P-value for the hypothesis that multi-task scores are better: 0.03125\n",
      "\n",
      "\n",
      "hart2016-Rpe1Avg \n",
      "Wilcoxon signed-rank test statistic: 7.0\n",
      "P-value for the hypothesis that multi-task scores are better: 0.59375\n",
      "\n",
      "\n",
      "morenoMateos2015 \n",
      "Wilcoxon signed-rank test statistic: 15.0\n",
      "P-value for the hypothesis that multi-task scores are better: 0.03125\n",
      "\n",
      "\n",
      "xu2015TrainHl60 \n",
      "Wilcoxon signed-rank test statistic: 12.0\n",
      "P-value for the hypothesis that multi-task scores are better: 0.15625\n",
      "\n",
      "\n",
      "xu2015TrainKbm7 \n",
      "Wilcoxon signed-rank test statistic: 11.0\n",
      "P-value for the hypothesis that multi-task scores are better: 0.21875\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "full_tl_spearmans = {'leenay ': [0.3945662992791584, 0.28886444285369967, 0.2832293550106096, 0.3812045384836776, 0.3084302670607356], 'chari2015Train293T ': [0.4840034728146655, 0.39761164549668365, 0.3600833233603445, 0.4589075364165655, 0.4139973976183702], 'doench2014-Hs ': [0.604398331720103, 0.6597718387710975, 0.6057318272692985, 0.6278606120194614, 0.6242418865126929], 'doench2014-Mm ': [0.6387138302444668, 0.5934436026524414, 0.5795445102497547, 0.6641364846173262, 0.6148725800377333], 'doench2016_hg19 ': [0.4470481639284342, 0.41205004580003385, 0.3806669944541304, 0.3778730665726853, 0.3799928286484724], 'doench2016plx_hg19 ': [0.34304373045576125, 0.34759628685165805, 0.37367568875797763, 0.30375648576553577, 0.3705712797436001], 'hart2016-Hct1162lib1Avg ': [0.4659833136989472, 0.48473653493773494, 0.5041149501992248, 0.4872644647899807, 0.5130336883582376], 'hart2016-HelaLib1Avg ': [0.4227210402520968, 0.41507376684075115, 0.5206980032268501, 0.46307037377937976, 0.45864263926680987], 'hart2016-HelaLib2Avg ': [0.5236502089619819, 0.5481012785158259, 0.5567806455340409, 0.5249603559422489, 0.5185740770786094], 'hart2016-Rpe1Avg ': [0.3676624665325396, 0.3202994036524485, 0.36569535268772574, 0.3201155183671906, 0.3378242304552371], 'morenoMateos2015 ': [0.511366110023212, 0.5596765872034264, 0.47864952541151023, 0.4863256126904982, 0.4559583295050568], 'xu2015TrainHl60 ': [0.6113603192701329, 0.5823703780109952, 0.6285548764329205, 0.6170997725390044, 0.6382557942005116], 'xu2015TrainKbm7 ': [0.6105208914068488, 0.6146143555741757, 0.604503486844718, 0.6264968451978611, 0.6425704986914227]}\n",
    "no_tl_spearmans = {'leenay ': [0.2281385635859052, 0.13219310196283862, 0.17645917742150882, 0.1991895168585149, 0.13898276685801456], 'chari2015Train293T ': [0.4851088717717332, 0.42951386869043234, 0.4962359970022284, 0.44006360140290673, 0.43403753322058536], 'doench2014-Hs ': [0.5694399426911336, 0.6308100074682227, 0.5638024482458861, 0.6335976610534575, 0.6474530091543474], 'doench2014-Mm ': [0.5012522846618047, 0.5876740969871228, 0.4937906744953973, 0.5365677207160734, 0.5611490099708824], 'doench2016_hg19 ': [0.4403594160715242, 0.4106923615359707, 0.3756922894941853, 0.4169719239142007, 0.38645087492718255], 'doench2016plx_hg19 ': [0.35016200196042946, 0.3290784970956178, 0.34812751892843996, 0.32756628449758607, 0.3287071549623779], 'hart2016-Hct1162lib1Avg ': [0.44295370403260315, 0.4414431359309001, 0.4658236452643802, 0.4195571470582503, 0.4550818737883262], 'hart2016-HelaLib1Avg ': [0.39296837160849796, 0.368512364313838, 0.4311021991434731, 0.4184207669006523, 0.3958302741644787], 'hart2016-HelaLib2Avg ': [0.4475427340702983, 0.4561188443513974, 0.4559988057406878, 0.4592909761379809, 0.4622346349316968], 'hart2016-Rpe1Avg ': [0.33966245945993606, 0.33258308919280144, 0.39453341579796086, 0.3236438557243008, 0.31807956291719613], 'morenoMateos2015 ': [0.17934169571467085, 0.1592087129216699, 0.2618979299036688, 0.20528662787267887, 0.21499883384808927], 'xu2015TrainHl60 ': [0.584968239227687, 0.5622220028454818, 0.6385630874949201, 0.6001132479439519, 0.6384349840648003], 'xu2015TrainKbm7 ': [0.5859855576374431, 0.5810070951689895, 0.6167067211185403, 0.6075523045996533, 0.6653562751876245]}\n",
    "\n",
    "datasets = [k for k in full_tl_spearmans.keys()]\n",
    "for dataset in datasets:\n",
    "    print(dataset)\n",
    "    test_performance(no_tl_spearmans[dataset], full_tl_spearmans[dataset])\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wilcoxon signed-rank test statistic: 1839.0\n",
      "P-value for the hypothesis that multi-task scores are better: 2.7352763537502853e-07\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1839.0, 2.7352763537502853e-07)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine all regardless of dataset\n",
    "full_tl_combined = []\n",
    "no_tl_combined = []\n",
    "for dataset in datasets:\n",
    "    full_tl_combined.extend(full_tl_spearmans[dataset])\n",
    "    no_tl_combined.extend(no_tl_spearmans[dataset])\n",
    "\n",
    "test_performance(no_tl_combined, full_tl_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wilcoxon signed-rank test statistic: 15.0\n",
      "P-value for the hypothesis that multi-task scores are better: 0.03125\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(15.0, 0.03125)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_tl_co_hela = full_tl_spearmans['hart2016-HelaLib2Avg ']\n",
    "no_tl_dhf_hela = [0.4325,0.4895,0.4730,0.4660,0.4922]\n",
    "\n",
    "test_performance(no_tl_dhf_hela, full_tl_co_hela)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wilcoxon signed-rank test statistic: 15.0\n",
      "P-value for the hypothesis that multi-task scores are better: 0.03125\n",
      "Wilcoxon signed-rank test statistic: 15.0\n",
      "P-value for the hypothesis that multi-task scores are better: 0.03125\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(15.0, 0.03125)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_tl_co_moreno = full_tl_spearmans['morenoMateos2015 ']\n",
    "full_tl_co_leenay = full_tl_spearmans['leenay ']\n",
    "\n",
    "no_tl_dhf_moreno = [0.2445,0.2091,0.3005,0.2212,0.3330]\n",
    "no_tl_dhf_leenay = [0.2759,0.0887,0.2057,0.1963,0.2155]\n",
    "\n",
    "test_performance(no_tl_dhf_moreno, full_tl_co_moreno)\n",
    "test_performance(no_tl_dhf_leenay, full_tl_co_leenay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wilcoxon signed-rank test statistic: 15.0\n",
      "P-value for the hypothesis that multi-task scores are better: 0.03125\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(15.0, 0.03125)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "worse = [0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "better = [0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "\n",
    "test_performance(worse, better)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
